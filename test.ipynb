{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'source'\n",
      "/home/labicquette/M1/TER/source\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%cd source\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import eval, pipeline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_eval = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 10:36:08 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:08 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:08 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:08 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n",
      "2024-03-13 10:36:08 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:08 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:08 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:08 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n",
      "2024-03-13 10:36:08 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:08 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:08 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:08 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.839622641509434 0.717741935483871 0.773913043478261 ../documents/train/California v. Greenwood_retagged.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 10:36:09 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:09 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:09 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:09 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n",
      "2024-03-13 10:36:09 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:09 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:09 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:09 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n",
      "2024-03-13 10:36:09 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:09 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:09 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:09 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6235294117647059 0.8153846153846154 0.7066666666666667 ../documents/train/opinion-G16-(Jenkins v. Georgia, 418 U.S. 153).htm.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 10:36:10 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:10 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:10 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:10 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746268656716418 0.8130081300813008 0.7782101167315176 ../documents/train/opinion-G16-(California v. Superior Court of Cal.,.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 10:36:10 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:10 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:10 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:10 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n",
      "2024-03-13 10:36:10 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:10 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:10 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:10 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n",
      "2024-03-13 10:36:11 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:11 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:11 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:11 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6422764227642277 0.6220472440944882 0.632 ../documents/train/opinion-G16-(Florida Power _ Light Co. v. Electric.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 10:36:11 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:11 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:11 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:11 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7209302325581395 0.6966292134831461 0.7085714285714286 ../documents/train/opinion-G16-(Shapiro v. McManus, 136 S. Ct. 450).h.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 10:36:12 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:12 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:12 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:12 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(models)):\n\u001b[1;32m      7\u001b[0m     start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 8\u001b[0m     r, p, f \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     res_eval \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [[time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart, r, p, f]]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(res_eval)\n",
      "File \u001b[0;32m~/M1/TER/source/pipeline.py:47\u001b[0m, in \u001b[0;36mevaluation\u001b[0;34m(dir_path, tokeniz, model)\u001b[0m\n\u001b[1;32m     45\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1_score\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m files :\n\u001b[0;32m---> 47\u001b[0m     p, r, f \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokeniz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ((p \u001b[38;5;241m+\u001b[39m r \u001b[38;5;241m+\u001b[39m f) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m )\u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.8\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m model \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnaive\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     49\u001b[0m         \u001b[38;5;28mprint\u001b[39m(p,r,f, file)\n",
      "File \u001b[0;32m~/M1/TER/source/pipeline.py:16\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(path, tokeniz, model)\u001b[0m\n\u001b[1;32m     11\u001b[0m experts \u001b[38;5;241m=\u001b[39m  getExperts(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataset_v20230110.tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m,path)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#print(\"experts\", experts)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#experts = [tokenizer(sentence, tokenizer=tokeniz) for sentence in experts]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#print(\"tokens experts\",experts)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#print(\"model\", model)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m seg \u001b[38;5;241m=\u001b[39m \u001b[43msegmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokeniz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m#print(\"Segmentation\", seg)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m saveSegmentation(path, seg, model)\n",
      "File \u001b[0;32m~/M1/TER/source/segmentation.py:35\u001b[0m, in \u001b[0;36msegmentation\u001b[0;34m(text, tokenizer, model, args)\u001b[0m\n\u001b[1;32m     33\u001b[0m     model\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 35\u001b[0m         output_file \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPunctuationSpace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_file\u001b[38;5;241m.\u001b[39mgetvalue()\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspacy\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m#tokenization\u001b[39;00m\n",
      "File \u001b[0;32m~/M1/TER/ersatz/ersatz/split.py:170\u001b[0m, in \u001b[0;36mEvalModel.split\u001b[0;34m(self, input_file, output_file, batch_size, candidates)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_file, output_file, batch_size, candidates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m input_file:\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_evaluation(line, batch_size, candidates\u001b[38;5;241m=\u001b[39mcandidates):\n\u001b[1;32m    171\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m batch_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(batch_output\u001b[38;5;241m.\u001b[39mstrip(), file\u001b[38;5;241m=\u001b[39moutput_file)\n",
      "File \u001b[0;32m~/M1/TER/ersatz/ersatz/split.py:128\u001b[0m, in \u001b[0;36mEvalModel.parallel_evaluation\u001b[0;34m(self, content, batch_size, candidates, min_sent_length)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_evaluation\u001b[39m(\u001b[38;5;28mself\u001b[39m, content, batch_size, candidates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, min_sent_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m--> 128\u001b[0m     batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatchify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     eos \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m contexts, factors, indices, \u001b[38;5;129;01min\u001b[39;00m batches:\n",
      "File \u001b[0;32m~/M1/TER/ersatz/ersatz/split.py:73\u001b[0m, in \u001b[0;36mEvalModel.batchify\u001b[0;34m(self, content, batch_size, candidates)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbatchify\u001b[39m(\u001b[38;5;28mself\u001b[39m, content, batch_size, candidates):\n\u001b[1;32m     72\u001b[0m     source_factors \u001b[38;5;241m=\u001b[39m SourceFactors()\n\u001b[0;32m---> 73\u001b[0m     left_contexts, right_contexts \u001b[38;5;241m=\u001b[39m \u001b[43msplit_test_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mleft_context_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mright_context_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(left_contexts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     75\u001b[0m         lines \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/M1/TER/ersatz/ersatz/dataset.py:89\u001b[0m, in \u001b[0;36msplit_test_file\u001b[0;34m(document, tokenizer, left_context_size, right_context_size)\u001b[0m\n\u001b[1;32m     87\u001b[0m temp_index \u001b[38;5;241m=\u001b[39m right_context_size \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(document, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 89\u001b[0m     left_contexts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_temp\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     91\u001b[0m     right_contexts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(right_temp))\n\u001b[1;32m     93\u001b[0m     left_temp\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dir_path = \"../documents/train/*\"\n",
    "model=\"nltk\"\n",
    "tokenizer= \"nltk-punkt\"\n",
    "models = ['ersatz','nltk', 'spacy', \"custom_spacy\", 'naive']\n",
    "tokenizers = ['ersatz', 'nltk-punkt', 'spacy', 'spacy', 'nltk-word']\n",
    "for i in range(len(models)):\n",
    "    start = time.time()\n",
    "    r, p, f = pipeline.evaluation(dir_path, tokenizers[i], models[i])\n",
    "    res_eval += [[time.time()-start, r, p, f]]\n",
    "print(res_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_c88f8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c88f8_level0_col0\" class=\"col_heading level0 col0\" >execution_time</th>\n",
       "      <th id=\"T_c88f8_level0_col1\" class=\"col_heading level0 col1\" >precision</th>\n",
       "      <th id=\"T_c88f8_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
       "      <th id=\"T_c88f8_level0_col3\" class=\"col_heading level0 col3\" >F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c88f8_level0_row0\" class=\"row_heading level0 row0\" >ersatz</th>\n",
       "      <td id=\"T_c88f8_row0_col0\" class=\"data row0 col0\" >nan</td>\n",
       "      <td id=\"T_c88f8_row0_col1\" class=\"data row0 col1\" >nan</td>\n",
       "      <td id=\"T_c88f8_row0_col2\" class=\"data row0 col2\" >nan</td>\n",
       "      <td id=\"T_c88f8_row0_col3\" class=\"data row0 col3\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c88f8_level0_row1\" class=\"row_heading level0 row1\" >nltk</th>\n",
       "      <td id=\"T_c88f8_row1_col0\" class=\"data row1 col0\" >nan</td>\n",
       "      <td id=\"T_c88f8_row1_col1\" class=\"data row1 col1\" >nan</td>\n",
       "      <td id=\"T_c88f8_row1_col2\" class=\"data row1 col2\" >nan</td>\n",
       "      <td id=\"T_c88f8_row1_col3\" class=\"data row1 col3\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c88f8_level0_row2\" class=\"row_heading level0 row2\" >spacy</th>\n",
       "      <td id=\"T_c88f8_row2_col0\" class=\"data row2 col0\" >nan</td>\n",
       "      <td id=\"T_c88f8_row2_col1\" class=\"data row2 col1\" >nan</td>\n",
       "      <td id=\"T_c88f8_row2_col2\" class=\"data row2 col2\" >nan</td>\n",
       "      <td id=\"T_c88f8_row2_col3\" class=\"data row2 col3\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c88f8_level0_row3\" class=\"row_heading level0 row3\" >custom_spacy</th>\n",
       "      <td id=\"T_c88f8_row3_col0\" class=\"data row3 col0\" >nan</td>\n",
       "      <td id=\"T_c88f8_row3_col1\" class=\"data row3 col1\" >nan</td>\n",
       "      <td id=\"T_c88f8_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
       "      <td id=\"T_c88f8_row3_col3\" class=\"data row3 col3\" >nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c88f8_level0_row4\" class=\"row_heading level0 row4\" >naive</th>\n",
       "      <td id=\"T_c88f8_row4_col0\" class=\"data row4 col0\" >nan</td>\n",
       "      <td id=\"T_c88f8_row4_col1\" class=\"data row4 col1\" >nan</td>\n",
       "      <td id=\"T_c88f8_row4_col2\" class=\"data row4 col2\" >nan</td>\n",
       "      <td id=\"T_c88f8_row4_col3\" class=\"data row4 col3\" >nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f97fc5c88b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "little_df = pd.DataFrame(res_eval,columns=[\"execution_time\",\"precision\", \"recall\", \"F1_score\"], index=[\"ersatz\", \"nltk\", \"spacy\", \"custom_spacy\", \"naive\"])\n",
    "little_df.style.highlight_max(color = 'green', axis = 0).highlight_max(color = 'red', axis = 0, subset = [\"execution_time\"]).highlight_min(color = 'red', axis = 0).highlight_min(color = 'green', axis = 0, subset = [\"execution_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 10:36:17 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:17 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:17 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:17 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n",
      "2024-03-13 10:36:18 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:18 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:18 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:18 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n",
      "2024-03-13 10:36:18 | INFO | ersatz | Segmentation model: \"en\"\n",
      "2024-03-13 10:36:18 | INFO | ersatz | Model description: \"monolingual/en\"\n",
      "2024-03-13 10:36:18 | INFO | ersatz | Release Date: \"01 June 2021\"\n",
      "2024-03-13 10:36:18 | INFO | ersatz | USING \"en\" model found at /home/labicquette/.ersatz/monolingual/en/01.Jun.21.en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181818181818182 0.7570093457943925 0.7864077669902914 ../documents/test/opinion-G16-(Return Mail, Inc. v. Postal Service,.txt\n",
      "0.7481481481481481 0.8211382113821138 0.7829457364341086 ../documents/test/Press Enterprise v Sup. Court_retagged_MCL.txt\n",
      "0.675 0.8709677419354839 0.7605633802816901 ../documents/test/opinion-G16-(Rogers v. Quan, 357 U.S. 193).html.txt\n",
      "0.7990196078431373 0.7616822429906542 0.7799043062200957 ../documents/test/opinion-G16-(Return Mail, Inc. v. Postal Service,.txt\n",
      "0.7105263157894737 0.8709677419354839 0.782608695652174 ../documents/test/opinion-G16-(Rogers v. Quan, 357 U.S. 193).html.txt\n",
      "[[0.8063530921936035, 0.8136617392703923, 0.9130486209679664, 0.8599027770220021], [0.12105822563171387, 0.8163717663706634, 0.7471099887766556, 0.7766389612353634], [0.6812732219696045, 0.8097993174686043, 0.7709415373857338, 0.7875043339574233], [0.13292241096496582, 0.3428004539315818, 0.20189413599898576, 0.25365913445472293]]\n"
     ]
    }
   ],
   "source": [
    "dir_path = \"../documents/test/*\"\n",
    "model=\"nltk\"\n",
    "tokenizer= \"nltk-punkt\"\n",
    "models = ['ersatz','nltk', 'spacy',  'naive']\n",
    "tokenizers = ['ersatz', 'nltk-punkt', 'spacy',  'nltk-word']\n",
    "for i in range(len(models)):\n",
    "    start = time.time()\n",
    "    r, p, f = pipeline.evaluation(dir_path, tokenizers[i], models[i])\n",
    "    res_eval += [[time.time()-start, r, p, f]]\n",
    "print(res_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_26b12_row0_col0 {\n",
       "  background-color: green;\n",
       "  background-color: red;\n",
       "}\n",
       "#T_26b12_row0_col2, #T_26b12_row0_col3, #T_26b12_row1_col1 {\n",
       "  background-color: green;\n",
       "}\n",
       "#T_26b12_row1_col0 {\n",
       "  background-color: red;\n",
       "  background-color: green;\n",
       "}\n",
       "#T_26b12_row3_col1, #T_26b12_row3_col2, #T_26b12_row3_col3 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_26b12\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_26b12_level0_col0\" class=\"col_heading level0 col0\" >execution_time</th>\n",
       "      <th id=\"T_26b12_level0_col1\" class=\"col_heading level0 col1\" >precision</th>\n",
       "      <th id=\"T_26b12_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
       "      <th id=\"T_26b12_level0_col3\" class=\"col_heading level0 col3\" >F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_26b12_level0_row0\" class=\"row_heading level0 row0\" >ersatz</th>\n",
       "      <td id=\"T_26b12_row0_col0\" class=\"data row0 col0\" >0.806353</td>\n",
       "      <td id=\"T_26b12_row0_col1\" class=\"data row0 col1\" >0.813662</td>\n",
       "      <td id=\"T_26b12_row0_col2\" class=\"data row0 col2\" >0.913049</td>\n",
       "      <td id=\"T_26b12_row0_col3\" class=\"data row0 col3\" >0.859903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26b12_level0_row1\" class=\"row_heading level0 row1\" >nltk</th>\n",
       "      <td id=\"T_26b12_row1_col0\" class=\"data row1 col0\" >0.121058</td>\n",
       "      <td id=\"T_26b12_row1_col1\" class=\"data row1 col1\" >0.816372</td>\n",
       "      <td id=\"T_26b12_row1_col2\" class=\"data row1 col2\" >0.747110</td>\n",
       "      <td id=\"T_26b12_row1_col3\" class=\"data row1 col3\" >0.776639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26b12_level0_row2\" class=\"row_heading level0 row2\" >spacy</th>\n",
       "      <td id=\"T_26b12_row2_col0\" class=\"data row2 col0\" >0.681273</td>\n",
       "      <td id=\"T_26b12_row2_col1\" class=\"data row2 col1\" >0.809799</td>\n",
       "      <td id=\"T_26b12_row2_col2\" class=\"data row2 col2\" >0.770942</td>\n",
       "      <td id=\"T_26b12_row2_col3\" class=\"data row2 col3\" >0.787504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_26b12_level0_row3\" class=\"row_heading level0 row3\" >naive</th>\n",
       "      <td id=\"T_26b12_row3_col0\" class=\"data row3 col0\" >0.132922</td>\n",
       "      <td id=\"T_26b12_row3_col1\" class=\"data row3 col1\" >0.342800</td>\n",
       "      <td id=\"T_26b12_row3_col2\" class=\"data row3 col2\" >0.201894</td>\n",
       "      <td id=\"T_26b12_row3_col3\" class=\"data row3 col3\" >0.253659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f9728993ee0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "little_df = pd.DataFrame(res_eval,columns=[\"execution_time\",\"precision\", \"recall\", \"F1_score\"], index=[\"ersatz\", \"nltk\", \"spacy\",  \"naive\"])\n",
    "little_df.style.highlight_max(color = 'green', axis = 0).highlight_max(color = 'red', axis = 0, subset = [\"execution_time\"]).highlight_min(color = 'red', axis = 0).highlight_min(color = 'green', axis = 0, subset = [\"execution_time\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
